{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZCjxsCaztqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb16bb7-5ced-45fe-95bb-7e12c88948de"
      },
      "source": [
        "# install necessary dependencies\n",
        "!pip install nltk\n",
        "!pip install gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vjf9tGp1LoV"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G954jKDz1QJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0626bc1d-bc4e-4779-db21-56788ee5b300"
      },
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uAsnQO2vguW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a444efca-c716-4966-e6fc-f321c1f6d1b8"
      },
      "source": [
        "#load dataset\n",
        "def loadDataset():\n",
        "    f = open('data4.csv','r',encoding='unicode_escape')\n",
        "    dataset = []\n",
        "    for line in f.readlines():\n",
        "        dataset.append(list(line.strip('\\n').split(' ')))\n",
        "    f.close()\n",
        "    return dataset\n",
        "dataset_raw = loadDataset()\n",
        "print(dataset_raw[0:2])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Japan', ',', 'Japan', 'is', 'an', 'island', 'country', 'in', 'East', 'Asia', 'Located', 'in', 'the', 'Pacific', 'Ocean', '£¬', 'it', 'lies', 'off', 'the', 'eastern', 'coast', 'of', 'the', 'Asian', 'continent', 'and', 'stretches', 'from', 'the', 'Sea', 'of', 'Okhotsk', 'in', 'the', 'north', 'to', 'the', 'East', 'China', 'Sea', 'and', 'the', 'Philippine', 'Sea', 'in', 'the', 'south', ''], ['United', 'States', ',', 'The', 'United', 'States', 'of', 'America', '(USA)', '£¬', 'commonly', 'known', 'as', 'the', 'United', 'States', '(US', 'or', 'US)', 'or', 'America', '£¬', 'is', 'a', 'country', 'comprising', '50', 'states', '£¬', 'a', 'federal', 'district', '£¬', 'five', 'major', 'self-governing', 'territories', '£¬', 'and', 'various', 'possessions[h]', 'At', '38', 'million', 'square', 'miles', '(98', 'million', 'km2)', '£¬', 'the', 'United', 'States', 'is', 'the', \"world's\", 'third', 'or', 'fourth', 'largest', 'country', 'by', 'total', 'area[d]', 'and', 'is', 'slightly', 'smaller', 'than', 'the', 'entire', 'continent', 'of', \"Europe's\", '39', 'million', 'square', 'miles', '(101', 'million', 'km2)', 'With', 'a', 'population', 'of', 'over', '327', 'million', 'people', '£¬', 'the', 'US', 'is', 'the', 'third', 'most', 'populous', 'country', 'The', 'capital', 'is', 'Washington', '£¬', 'DC', '£¬', 'and', 'the', 'most', 'populous', 'city', 'is', 'New', 'York', 'City', 'Forty-eight', 'states', 'and', 'the', \"capital's\", 'federal', 'district', 'are', 'contiguous', 'in', 'North', 'America', 'between', 'Canada', 'and', 'Mexico', 'The', 'State', 'of', 'Alaska', 'is', 'in', 'the', 'northwest', 'corner', 'of', 'North', 'America', '£¬', 'bordered', 'by', 'Canada', 'to', 'the', 'east', 'and', 'across', 'the', 'Bering', 'Strait', 'from', 'Russia', 'to', 'the', 'west', 'The', 'State', 'of', 'Hawaii', 'is', 'an', 'archipelago', 'in', 'the', 'mid-Pacific', 'Ocean', 'The', 'US', 'territories', 'are', 'scattered', 'about', 'the', 'Pacific', 'Ocean', 'and', 'the', 'Caribbean', 'Sea', '£¬', 'stretching', 'across', 'nine', 'official', 'time', 'zones', 'The', 'extremely', 'diverse', 'geography', '£¬', 'climate', '£¬', 'and', 'wildlife', 'of', 'the', 'United', 'States', 'make', 'it', 'one', 'of', 'the', \"world's\", '17', 'megadiverse', 'countries[21]', 'Paleo-Indians', 'migrated', 'from', 'Siberia', 'to', 'the', 'North', 'American', 'mainland', 'at', 'least', '12', '£¬000', 'years', 'ago[22]', 'European', 'colonization', 'began', 'in', 'the', '16th', 'century', 'The', 'United', 'States', 'emerged', 'from', 'the', 'thirteen', 'British', 'colonies', 'established', 'along', 'the', 'East', 'Coast', 'Following', 'the', 'French', 'and', 'Indian', 'War', '£¬', 'numerous', 'disputes', 'between', 'Great', 'Britain', 'and', 'the', 'colonies', 'led', 'to', 'the', 'American', 'Revolution', '£¬', 'which', 'began', 'in', '1775', '£¬', 'and', 'the', 'subsequent', 'Declaration', 'of', 'Independence', 'in', '1776', 'The', 'war', 'ended', 'in', '1783', 'with', 'the', 'United', 'States', 'becoming', 'the', 'first', 'country', 'to', 'gain', 'independence', 'from', 'a', 'European', 'power[23]', 'The', 'current', 'constitution', 'was', 'adopted', 'in', '1788', '£¬', 'with', 'the', 'first', 'ten', 'amendments', '£¬', 'collectively', 'named', 'the', 'Bill', 'of', 'Rights', '£¬', 'being', 'ratified', 'in', '1791', 'to', 'guarantee', 'many', 'fundamental', 'civil', 'liberties', 'The', 'United', 'States', 'embarked', 'on', 'a', 'vigorous', 'expansion', 'across', 'North', 'America', 'throughout', 'the', '19th', 'century', '£¬', 'acquiring', 'new', 'territories', '£¬[24]', 'displacing', 'Native', 'American', 'tribes', '£¬', 'and', 'gradually', 'admitting', 'new', 'states', 'until', 'it', 'spanned', 'the', 'continent', 'by', '1848[24]', 'During', 'the', 'second', 'half', 'of', 'the', '19th', 'century', '£¬', 'the', 'Civil', 'War', 'led', 'to', 'the', 'abolition', 'of', 'slavery[25][26]', 'By', 'the', 'end', 'of', 'the', 'century', '£¬', 'the', 'United', 'States', 'had', 'extended', 'into', 'the', 'Pacific', 'Ocean', '£¬[27]', 'and', 'its', 'economy', '£¬', 'driven', 'in', 'large', 'part', 'by', 'the', 'Industrial', 'Revolution', '£¬', 'began', 'to', 'soar[28]', 'The', 'Spanishâ\\x80\\x93American', 'War', 'and', 'World', 'War', 'I', 'confirmed', 'the', \"country's\", 'status', 'as', 'a', 'global', 'military', 'power', 'The', 'United', 'States', 'emerged', 'from', 'World', 'War', 'II', 'as', 'a', 'global', 'superpower', '£¬', 'the', 'first', 'country', 'to', 'develop', 'nuclear', 'weapons', '£¬', 'the', 'only', 'country', 'to', 'use', 'them', 'in', 'warfare', '£¬', 'and', 'a', 'permanent', 'member', 'of', 'the', 'United', 'Nations', 'Security', 'Council', 'Sweeping', 'civil', 'rights', 'legislation', '£¬', 'notably', 'the', 'Civil', 'Rights', 'Act', 'of', '1964', '£¬', 'the', 'Voting', 'Rights', 'Act', 'of', '1965', 'and', 'the', 'Fair', 'Housing', 'Act', 'of', '1968', '£¬', 'outlawed', 'discrimination', 'based', 'on', 'race', 'or', 'color', 'During', 'the', 'Cold', 'War', '£¬', 'the', 'United', 'States', 'and', 'the', 'Soviet', 'Union', 'competed', 'in', 'the', 'Space', 'Race', '£¬', 'culminating', 'with', 'the', '1969', 'US', 'Moon', 'landing', 'The', 'end', 'of', 'the', 'Cold', 'War', 'and', 'the', 'collapse', 'of', 'the', 'Soviet', 'Union', 'in', '1991', 'left', 'the', 'United', 'States', 'as', 'the', \"world's\", 'sole', 'superpower[29]', 'The', 'United', 'States', 'is', 'the', \"world's\", 'oldest', 'surviving', 'federation', 'It', 'is', 'a', 'federal', 'republic', 'and', 'a', 'representative', 'democracy', 'The', 'United', 'States', 'is', 'a', 'founding', 'member', 'of', 'the', 'United', 'Nations', '£¬', 'World', 'Bank', '£¬', 'International', 'Monetary', 'Fund', '£¬', 'Organization', 'of', 'American', 'States', '(OAS)', '£¬', 'and', 'other', 'international', 'organizations', 'The', 'United', 'States', 'is', 'a', 'highly', 'developed', 'country', '£¬', 'with', 'the', \"world's\", 'largest', 'economy', 'by', 'nominal', 'GDP', 'and', 'second-largest', 'economy', 'by', 'PPP', '£¬', 'accounting', 'for', 'approximately', 'a', 'quarter', 'of', 'global', 'GDP[30]', 'The', 'US', 'economy', 'is', 'largely', 'post-industrial', '£¬', 'characterized', 'by', 'the', 'dominance', 'of', 'services', 'and', 'knowledge-based', 'activities', '£¬', 'although', 'the', 'manufacturing', 'sector', 'remains', 'the', 'second-largest', 'in', 'the', 'world[31]', 'The', 'United', 'States', 'is', 'the', \"world's\", 'largest', 'importer', 'and', 'the', 'second', 'largest', 'exporter', 'of', 'goods', '£¬', 'by', 'value[32][33]', 'Although', 'its', 'population', 'is', 'only', '43%', 'of', 'the', 'world', 'total', '£¬[34]', 'the', 'US', 'holds', '31%', 'of', 'the', 'total', 'wealth', 'in', 'the', 'world', '£¬', 'the', 'largest', 'share', 'of', 'global', 'wealth', 'concentrated', 'in', 'a', 'single', 'country[35]', 'Despite', 'income', 'and', 'wealth', 'disparities', '£¬', 'the', 'United', 'States', 'continues', 'to', 'rank', 'very', 'high', 'in', 'measures', 'of', 'socioeconomic', 'performance', '£¬', 'including', 'average', 'wage', '£¬', 'human', 'development', '£¬', 'per', 'capita', 'GDP', '£¬', 'and', 'worker', 'productivity[36][37]', 'The', 'United', 'States', 'is', 'the', 'foremost', 'military', 'power', 'in', 'the', 'world', '£¬', 'making', 'up', 'a', 'third', 'of', 'global', 'military', 'spending', '£¬[38]', 'and', 'is', 'a', 'leading', 'political', '£¬', 'cultural', '£¬', 'and', 'scientific', 'force', 'internationally[39]']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbz3co3mVFiK"
      },
      "source": [
        "#preprocess\n",
        "from nltk.corpus import wordnet as wn \n",
        "\n",
        "en_stop = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "en_stop = [\"``\",\"/\",\",.\",\".,\",\";\",\"--\",\":\",\")\",\"(\",'\"','&',\"'\",'),',',\"','-','.,','.,\"','.-',\"?\",\">\",\"<\"]                  \\\n",
        "         +[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"86\",\"1986\",\"1987\",\"000\"]                                                      \\\n",
        "         +[\"said\",\"say\",\"u\",\"v\",\"mln\",\"ct\",\"net\",\"dlrs\",\"tonne\",\"pct\",\"shr\",\"nil\",\"company\",\"lt\",\"share\",\"year\",\"billion\",\"price\"]          \\\n",
        "         +en_stop\n",
        "\n",
        "def preprocess_word(word, stopwordset):\n",
        "    \n",
        "    word=word.lower()\n",
        "    \n",
        "    if word in [\",\",\".\",\"£¬\"]:\n",
        "        return None\n",
        "    \n",
        "    if word in stopwordset:\n",
        "        return None\n",
        "    \n",
        "    lemma = wn.morphy(word)\n",
        "    if lemma is None:\n",
        "        return word\n",
        "\n",
        "    elif lemma in stopwordset: \n",
        "        return None\n",
        "    else:\n",
        "        return lemma\n",
        "    \n",
        "\n",
        "def preprocess_document(document):\n",
        "    document=[preprocess_word(w, en_stop) for w in document]\n",
        "    document=[w for w in document if w is not None]\n",
        "    return document\n",
        "\n",
        "def preprocess_documents(documents):\n",
        "    return [preprocess_document(document) for document in documents]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gemDoQ7hL-09",
        "outputId": "15c432b9-da63-49b3-d7f2-a67de5f7dc39"
      },
      "source": [
        " dataset = preprocess_documents(dataset_raw)\n",
        " print(dataset[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['japan', 'japan', 'island', 'country', 'east', 'asia', 'locate', 'pacific', 'ocean', 'lie', 'eastern', 'coast', 'asian', 'continent', 'stretch', 'sea', 'okhotsk', 'north', 'east', 'china', 'sea', 'philippine', 'sea', 'south', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avMtargc-GdB"
      },
      "source": [
        "#vectorization with tf-idf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def transform(dataset,n_features=1000):\n",
        "    pre_data=[\" \".join(doc) for doc in dataset]\n",
        "    vectorizer = TfidfVectorizer(max_features=200, token_pattern=u'(?u)\\\\b\\\\w+\\\\b' )\n",
        "    X = vectorizer.fit_transform(pre_data)\n",
        "    return X,vectorizer\n",
        "\n",
        "X, vectorizer = transform(dataset)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU2prkHo_5Oo",
        "outputId": "27ce5195-f818-4e64-83ab-7eb80a84b55b"
      },
      "source": [
        "#clustering with k-means\n",
        "num_clusters = 5\n",
        "km = KMeans(n_clusters=num_clusters, random_state = 0)\n",
        "# fit\n",
        "clusters = km.fit_predict(X)\n",
        "\n",
        "for doc, cls in zip(dataset, clusters):\n",
        "  if cls == 0:\n",
        "    print(doc[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "moldova\n",
            "ukraine\n",
            "belarus\n",
            "poland\n",
            "georgia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_pM4mvlIIDO",
        "outputId": "e73b5ab5-2380-4dea-b58f-2dacef31590a"
      },
      "source": [
        "#evaluate with Silhouette Coefficient\n",
        "from sklearn import metrics\n",
        "print(metrics.silhouette_score(X, clusters, metric='euclidean'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.033640139409598965\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}